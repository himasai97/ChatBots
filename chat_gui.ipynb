{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Importing the neccessary libraries, loading the required data, and training the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Step: 11999  | total loss: \u001b[1m\u001b[32m0.02099\u001b[0m\u001b[0m | time: 0.033s\n",
      "| Adam | epoch: 1000 | loss: 0.02099 - acc: 0.9948 -- iter: 88/90\n",
      "Training Step: 12000  | total loss: \u001b[1m\u001b[32m0.01930\u001b[0m\u001b[0m | time: 0.036s\n",
      "| Adam | epoch: 1000 | loss: 0.01930 - acc: 0.9953 -- iter: 90/90\n",
      "--\n",
      "INFO:tensorflow:c:\\Users\\himas\\Downloads\\Learning_projects\\VS_code\\Chat_bot\\model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO:tensorflow:Restoring parameters from c:\\Users\\himas\\Downloads\\Learning_projects\\VS_code\\Chat_bot\\model.tflearn\n"
     ]
    }
   ],
   "source": [
    "# run the bot notebook to train the model and store it\n",
    "%run bot.ipynb\n",
    "\n",
    "# for proccessing the test data(chats from the user)\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# for loading data\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# basic libraries to access and manipulate our arrays \n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# loading the data\n",
    "intents = json.loads(open('intents.json').read())\n",
    "words = pickle.load(open('words.pkl','rb'))\n",
    "classes = pickle.load(open('classes.pkl','rb'))\n",
    "\n",
    "# loading the trained model\n",
    "model.load('./model.tflearn')"
   ]
  },
  {
   "source": [
    "# Functions for processing the test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nInput sentence : 'How to apply for teaching position?'\n\nFound in bag: apply\n\nFound in bag: teaching\n\nFound in bag: position\n\nbag of words: [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n 0 0]\n"
     ]
    }
   ],
   "source": [
    "def get_words(sent):\n",
    "    '''\n",
    "    to break a sentence and get the processed words\n",
    "    Parameters:\n",
    "            sent: the sentence to be processed, a scalar string\n",
    "    Returns:\n",
    "            sentence_words: an array of lemmatized and lowered words tokenized from the sentence\n",
    "    '''\n",
    "    # tokenize the sentence\n",
    "    token_w = nltk.word_tokenize(sent)\n",
    "    # lemmatize and lower the words\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in token_w]\n",
    "    return sentence_words\n",
    "\n",
    "def vectorize_sent(sent, words, show_details=False):\n",
    "    '''\n",
    "    return bag of words vector, with 1 if word in the bag exists in the sentence, 0 otherwise\n",
    "    Parameters:\n",
    "            sent: the sentence to be processed, a scalar string\n",
    "            words: an array of all the processed words present in the training document\n",
    "            show_details: a boolean to indicate if the details involved in proccessing the data should be displayed for testing purposes\n",
    "    Returns:\n",
    "            a bag of words array that is given as input to the model (X_test)\n",
    "    '''\n",
    "    # get the words\n",
    "    sentence_words = get_words(sent)\n",
    "    # initialize the bag of words vector\n",
    "    bag_of_words = [0]*len(words)\n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s:\n",
    "                bag_of_words[i] = 1\n",
    "                if show_details:\n",
    "                    print(f'\\nFound in bag: {w}')\n",
    "\n",
    "    return (np.array(bag_of_words))\n",
    "\n",
    "# to check\n",
    "print(\"\\nInput sentence : \\'How to apply for teaching position?\\'\")\n",
    "p = vectorize_sent('How to apply for teaching position?', words, show_details=True)\n",
    "print(f\"\\nbag of words: {p}\")"
   ]
  },
  {
   "source": [
    "# Functions to get response from the model "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the threshold: consider the response only if the model probability of that class is beyond the threshold\n",
    "ERROR_THRESHOLD = 0.25\n",
    "\n",
    "# create a data structure to hold user context\n",
    "context = {}\n",
    "\n",
    "def predict_class(sent):\n",
    "    '''\n",
    "    Obtain the likelihood of the given sentence belonging to one of the classes listed\n",
    "    Parameters:\n",
    "            sent: the sentence to be analyzed, a scalar string\n",
    "    Returns:\n",
    "            results: an array of tuples, representing the class and its probability of being the result for the sentence\n",
    "    '''\n",
    "    # generate probabilities using the model\n",
    "    results = model.predict([vectorize_sent(sent, words)])[0]\n",
    "    # filter out predictions below the error threshold and create tuples of intent and probability for each result\n",
    "    results = [(classes[i],r) for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "    # sort by prediction confidence (probability)\n",
    "    results.sort(key=lambda x: x[1], reverse = True)\n",
    "    return results\n",
    "\n",
    "def bot_response(sent, userID = '123', show_details = False):\n",
    "    '''\n",
    "    Obtain the response by the model for the given input sentence\n",
    "    Parameters:\n",
    "            sent: the input sentence by the user, a scalar string\n",
    "            userID: the unique ID representing each user, needed to save the context unique to each user\n",
    "            show_details: a boolean to indicate if the details involved in obtaining the response should be displayed for testing purposes\n",
    "    Returns: \n",
    "            a random choice of response, a scalar string\n",
    "                the model predicts the given sentence to belong to a specific class, and \n",
    "                a response is selected from the array of responses included for that class, based on the context established for the user\n",
    "    '''\n",
    "    results = predict_class(sent)\n",
    "    print(results)\n",
    "    flag = True\n",
    "    # find the intent tag for the best result based on CONTEXT\n",
    "    if results:\n",
    "        # loop all possible matches to find a context appropriate response\n",
    "        for match in results:\n",
    "            for i in intents['intents']:\n",
    "                # find the tag that is in match\n",
    "                if i['tag'] == match[0]:\n",
    "                    if show_details: print('match: ', match)\n",
    "                    # set the context if it exists for the matched intent\n",
    "                    if 'context_set' in i:\n",
    "                        if show_details: print('context:', i['context_set'])\n",
    "                        context[userID] = i['context_set']\n",
    "\n",
    "                    # return a response if the matched intent is : \n",
    "                    # (1) not contextual, or \n",
    "                    # (2) contextual and applies to the given user's conversation\n",
    "                    if not 'context_filter' in i or \\\n",
    "                        (userID in context and 'context_filter' in i and i['context_filter'] == context[userID]):\n",
    "                        flag = False\n",
    "                        if show_details: print('tag:', i['tag'])\n",
    "                        return (random.choice(i['responses']))\n",
    "    \n",
    "    # if none of the responses satisfy the requirement, return the deafult response\n",
    "    if flag:\n",
    "        i = intents['intents'][0]\n",
    "        if show_details: print('default_tag:', i['tag'])\n",
    "        return (random.choice(i['responses']))\n"
   ]
  },
  {
   "source": [
    "# Creating a Graphical User Interface (GUI) using tkinter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('greeting', 0.9986443)]\n",
      "match:  ('greeting', 0.9986443)\n",
      "tag: greeting\n",
      "[('STEMforall', 0.98270226)]\n",
      "match:  ('STEMforall', 0.98270226)\n",
      "tag: STEMforall\n",
      "[('partners', 0.99450606)]\n",
      "match:  ('partners', 0.99450606)\n",
      "tag: partners\n",
      "[('lead', 0.9341583)]\n",
      "match:  ('lead', 0.9341583)\n",
      "match:  ('lead', 0.9341583)\n",
      "default_tag: greeting\n",
      "[('enrollment', 0.9834743)]\n",
      "match:  ('enrollment', 0.9834743)\n",
      "tag: enrollment\n",
      "[('greeting', 0.45839292), ('thanks', 0.33923328)]\n",
      "match:  ('greeting', 0.45839292)\n",
      "tag: greeting\n",
      "[('greeting', 0.45839292), ('thanks', 0.33923328)]\n",
      "match:  ('greeting', 0.45839292)\n",
      "tag: greeting\n",
      "[('tutor_application', 0.98017603)]\n",
      "match:  ('tutor_application', 0.98017603)\n",
      "context: ['application']\n",
      "tag: tutor_application\n"
     ]
    }
   ],
   "source": [
    "# import functions from tkinter\n",
    "import tkinter\n",
    "from tkinter import *\n",
    "\n",
    "def send():\n",
    "    '''\n",
    "    take input from the user and send the response obtained from the model\n",
    "    components used:\n",
    "        ChatLog: the chat window\n",
    "        EntryBox: the box inside the chat window to enter the message\n",
    "        ScrollBar: bind a scrollbar to the chat window\n",
    "        SendButton: the button for sending the message\n",
    "    '''\n",
    "    msg = EntryBox.get(\"1.0\", 'end-1c').strip()\n",
    "    EntryBox.delete(\"0.0\",END)\n",
    "\n",
    "    if msg !='':\n",
    "        ChatLog.config(state=NORMAL)\n",
    "        ChatLog.insert(END, 'You: '+ msg + '\\n\\n')\n",
    "        ChatLog.config(foreground=\"#442265\", font = ('Verdana', 12))\n",
    "        \n",
    "        res = bot_response(msg,show_details=True)\n",
    "        ChatLog.insert(END, 'Bot: ' + res + '\\n\\n')\n",
    "        ChatLog.config(state=DISABLED)\n",
    "        ChatLog.yview(END)\n",
    "\n",
    "base = Tk()\n",
    "base.title(\"ChatBot\")\n",
    "base.geometry(\"375x470\")\n",
    "base.resizable(width=FALSE, height=FALSE)\n",
    "\n",
    "# create chat window\n",
    "ChatLog = Text(base, bd=0, bg='white', height='8', width='50', font='Arial')\n",
    "\n",
    "ChatLog.config(state=DISABLED)\n",
    "\n",
    "# bind scrollbar to chat window\n",
    "scrollbar = Scrollbar(base, command=ChatLog.yview, cursor='heart')\n",
    "ChatLog['yscrollcommand'] = scrollbar.set\n",
    "\n",
    "# create button to send message\n",
    "SendButton = Button(base, font=('Verdana', 12, 'bold'), text='Send', width='12', height='5', bd=0, bg='#32de97', activebackground='#3c9d9b', fg='#ffffff', command=send)\n",
    "\n",
    "# create the box to enter message\n",
    "EntryBox = Text(base, bd=0, bg='white', width='29', height='5', font='Arial')\n",
    "\n",
    "#place all components on the screen\n",
    "scrollbar.place(x=356, y=6, height=386)\n",
    "ChatLog.place(x=6, y=6, height=386, width=347)\n",
    "EntryBox.place(x=128, y=401, height=60, width=265)\n",
    "SendButton.place(x=6, y=401, height=60)\n",
    "\n",
    "ChatLog.config(state=NORMAL)\n",
    "# the first message seen on the chat window\n",
    "ChatLog.insert(END,\"Bot: Hello there! Welcome to STEMforall. I'm a Bot, here to answer any questions you have about our services.\\n\\n\")\n",
    "ChatLog.config(foreground=\"#442265\", font = ('Verdana', 12))\n",
    "ChatLog.config(state=DISABLED)\n",
    "\n",
    "# create an infinite loop used to run the application, \n",
    "# wait for an event to occur and process the event as long as the window is not closed.\n",
    "base.mainloop()\n"
   ]
  }
 ]
}